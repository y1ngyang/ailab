{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice node and edges \n",
    "https://www.cl.cam.ac.uk/~cm542/teaching/2010/stna-pdfs/stna-lecture8.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('quakers_nodelist.csv', 'r') as nodecsv: # Open the file                       \n",
    "    nodereader = csv.reader(nodecsv) # Read the csv  \n",
    "    # Retrieve the data (using Python list comprhension and list slicing to remove the header row, see footnote 3)\n",
    "    nodes = [n for n in nodereader][1:]                     \n",
    "\n",
    "node_names = [n[0] for n in nodes] # Get a list of only the node names                                       \n",
    "\n",
    "with open('quakers_edgelist.csv', 'r') as edgecsv: # Open the file\n",
    "    edgereader = csv.reader(edgecsv) # Read the csv     \n",
    "    edges = [tuple(e) for e in edgereader][1:] # Retrieve the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(node_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have a list of nodes (node_names) and a list of edges (edges). Now using networkx we add these.\n",
    "source:\n",
    "https://networkx.github.io/documentation/stable/tutorial.html#adding-attributes-to-graphs-nodes-and-edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "#initialize the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(node_names)\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Attributes\n",
    "Using fuctions: nx.set_node_attributes() and nx.set_edge_attributes(). \n",
    "First create a Python dictionary, where node names = keys and attributes = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_sig_dict = {}\n",
    "gender_dict = {}\n",
    "birth_dict = {}\n",
    "death_dict = {}\n",
    "id_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check index of each attribute and make loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes: # Loop through the list, one row at a time\n",
    "    hist_sig_dict[node[0]] = node[1]\n",
    "    gender_dict[node[0]] = node[2]\n",
    "    birth_dict[node[0]] = node[3]\n",
    "    death_dict[node[0]] = node[4]\n",
    "    id_dict[node[0]] = node[5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add attributes to the corresponding dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, hist_sig_dict, 'historical_significance')\n",
    "nx.set_node_attributes(G, gender_dict, 'gender')\n",
    "nx.set_node_attributes(G, birth_dict, 'birth_year')\n",
    "nx.set_node_attributes(G, death_dict, 'death_year')\n",
    "nx.set_node_attributes(G, id_dict, 'sdfb_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in G.nodes(): \n",
    "    print(n, G.node[n]['historical_significance']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in G.nodes(): # Loop through every node, in our data \"n\" = name \n",
    "    print(n, G.node[n]['birth_year']) # Access every node by its name by the attribute \"birth_year\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = nx.density(G)\n",
    "print(\"Network density:\", density)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fell_whitehead_path = nx.shortest_path(G, source=\"Margaret Fell\", target=\"George Whitehead\")\n",
    "\n",
    "print(\"Shortest path between Fell and Whitehead:\", fell_whitehead_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([p for p in nx.all_shortest_paths(G, source=\"Margaret Fell\", target=\"George Whitehead\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.astar_path(G, source=\"Margaret Fell\", target=\"George Whitehead\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.connectivity import local_node_connectivity\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.node_connectivity(G, s=\"Margaret Fell\", t=\"George Whitehead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.flow import shortest_augmenting_path\n",
    "nx.node_connectivity(G, s=\"Margaret Fell\", t=\"George Whitehead\", flow_func=shortest_augmenting_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_fox_path = nx.shortest_path(G,source= \"William Penn\", target=\"George Fox\")\n",
    "print(penn_fox_path)\n",
    "nx.node_connectivity(G, s=\"William Penn\", t=\"George Fox\", flow_func=shortest_augmenting_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of that path:\", len(fell_whitehead_path)-1)\n",
    "print(\"Length of that path:\", len(penn_fox_path)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your Graph has more than one component, this will return False:\n",
    "print(nx.is_connected(G))\n",
    "\n",
    "# Next, use nx.connected_components to get the list of components,\n",
    "# then use the max() command to find the largest one:\n",
    "components = nx.connected_components(G)\n",
    "largest_component = max(components, key=len)\n",
    "print(largest_component)\n",
    "\n",
    "# Create a \"subgraph\" of just the largest component\n",
    "# Then calculate the diameter of the subgraph, just like you did with density.\n",
    "#\n",
    "\n",
    "subgraph = G.subgraph(largest_component)\n",
    "diameter = nx.diameter(subgraph)\n",
    "print(\"Network diameter of largest component:\", diameter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By seeing the number of connections/degrees we can tell if it's directed or not. \n",
    "Density: ratio of actual edges in the network to all possible edges in the network\n",
    "Basic information on the dataset:\n",
    "network is undirected, thus, must use metrics that require symmetric edges between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triadic_closure = nx.transitivity(G)\n",
    "print(\"Triadic closure:\", triadic_closure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_dict = dict(G.degree(G.nodes()))\n",
    "nx.set_node_attributes(G, degree_dict, 'degree')\n",
    "\n",
    "print(G.node['William Penn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_degree = sorted(degree_dict.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 20 nodes by degree:\")\n",
    "for d in sorted_degree[:20]:\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_dict = nx.betweenness_centrality(G) # Run betweenness centrality\n",
    "eigenvector_dict = nx.eigenvector_centrality(G) # Run eigenvector centrality\n",
    "\n",
    "# Assign each to an attribute in your network\n",
    "nx.set_node_attributes(G, betweenness_dict, 'betweenness')\n",
    "nx.set_node_attributes(G, eigenvector_dict, 'eigenvector')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_betweenness = sorted(betweenness_dict.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "print(\"Top 20 nodes by betweenness centrality:\")\n",
    "for b in sorted_betweenness[:20]:\n",
    "    print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the top 20 nodes by betweenness as a list\n",
    "top_betweenness = sorted_betweenness[:20]\n",
    "\n",
    "#Then find and print their degree\n",
    "for tb in top_betweenness: # Loop through top_betweenness\n",
    "    degree = degree_dict[tb[0]] # Use degree_dict to access a node's degree, see footnote 2\n",
    "    print(\"Name:\", tb[0], \"| Betweenness Centrality:\", tb[1], \"| Degree:\", degree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.node_connectivity(G, s=\"William Penn\", t=\"George Whitehead\", flow_func=shortest_augmenting_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.has_bridges(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(nx.bridges(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "def breadth_first_search(g, source): \n",
    "    queue = deque([(None, source)]) \n",
    "    enqueued = set([source]) \n",
    "    while queue:\n",
    "        parent,n = queue.popleft() \n",
    "    yield  parent,n\n",
    "    new = set(g[n]) \n",
    "\n",
    "    enqueued \n",
    "    enqueued |= new \n",
    "    queue.extend([(n, child) for child in new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breadth_first_search(G, source= 'William Penn')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triangles(g):\n",
    "    for n1 in g.nodes:\n",
    "        neighbors1 = set(g[n1])\n",
    "        for n2 in filter(lambda x: x>n1, nodes):\n",
    "            neighbors2 = set(g[n2]) \n",
    "            common = neighbors1 & neighbors2\n",
    "            for n3 in filter(lambda x: x>n2, common):\n",
    "                yield n1,n2,n3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_triangles(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_neigh_degree(g):\n",
    "    data = {}\n",
    "    for n in g.nodes():\n",
    "        if g.degree(n):\n",
    "            data[n] = float(sum(g.degree(i) for i in g[n]))\n",
    "            g.degree(n)\n",
    "            return data\n",
    "def avg_neigh_degree(g):\n",
    "     return dict((n,float(sum(g.degree(i) for i in g[n]))/\n",
    "g.degree(n))  for n in g.nodes() if g.degree(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_neigh_degree(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hartford = nx.read_edgelist('hartford.txt',\n",
    "        create_using=nx.DiGraph(),nodetype=int)\n",
    "N,K = hartford.order(), hartford.size()\n",
    "avg_deg = float(K)/N\n",
    "print (\"Nodes: \", N)\n",
    "print (\"Edges: \", K)\n",
    "print (\"Average degree: \", avg_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_triangles(hartford)\n",
    "\n",
    "\n",
    "avg_neigh_degree(hartford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breadth_first_search(G, source= 213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_degrees  = hartford.in_degree() \n",
    "\n",
    "# dictionary node:degree\n",
    "in_values = {sorted(set(in_degrees.values()))} \n",
    "in_hist = [in_degrees.values().count(x) for x in in_values]\n",
    "plt.figure()\n",
    "plt.plot(in_values,in_hist,'ro-') \n",
    "# in-degree\n",
    "plt.plot(out_values,out_hist,'bv-') \n",
    "# out-degree\n",
    "plt.legend(['In-degree','Out-degree'])\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Number of nodes')\n",
    "plt.title('Hartford drug users network')\n",
    "plt.savefig('hartford_degree_distribution.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(nx.bridges(hartford))\n",
    "hartford.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hartford.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_dict = nx.betweenness_centrality(hartford) # Run betweenness centrality\n",
    "nx.set_node_attributes(hartford, betweenness_dict, 'betweenness')\n",
    "print(betweenness_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.utils import groups\n",
    "\n",
    "\n",
    "class UnionFind:\n",
    "    \n",
    "    def __init__(self, elements=None):\n",
    "        \n",
    "        if elements is None:\n",
    "            elements = ()\n",
    "        self.parents = {}\n",
    "        self.weights = {}\n",
    "        for x in elements:\n",
    "            self.weights[x] = 1\n",
    "            self.parents[x] = x\n",
    "\n",
    "        def __getitem__(self, object):\n",
    "        \n",
    "        # check for previously unknown object\n",
    "            if object not in self.parents:\n",
    "                self.parents[object] = object\n",
    "                self.weights[object] = 1\n",
    "                return object\n",
    "\n",
    "        # find path of objects leading to the root\n",
    "        path = [object]\n",
    "        root = self.parents[object]\n",
    "        while root != path[-1]:\n",
    "            path.append(root)\n",
    "            root = self.parents[root]\n",
    "\n",
    "        # compress the path and return\n",
    "        for ancestor in path:\n",
    "            self.parents[ancestor] = root\n",
    "        return root\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        return iter(self.parents)\n",
    "\n",
    "    def to_sets(self):\n",
    "        \n",
    "        # TODO In Python 3.3+, this should be `yield from ...`.\n",
    "        for block in groups(self.parents).values():\n",
    "            yield block[docs]\n",
    "def union(self, *objects):\n",
    "        \"\"\"Find the sets containing the objects and merge them all.\"\"\"\n",
    "        roots = [self[x] for x in objects]\n",
    "        # Find the heaviest root according to its weight.\n",
    "        heaviest = max(roots, key=lambda r: self.weights[r])\n",
    "        for r in roots:\n",
    "            if r != heaviest:\n",
    "                self.weights[heaviest] += self.weights[r]\n",
    "                self.parents[r] = heaviest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "networkx.utils.is_string_like('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dg = nx.DiGraph()\n",
    "hartford.add_weighted_edges_from([(1,4,0.5), (3,1,0.75)])\n",
    "hartford.out_degree(1)\n",
    "\n",
    "hartford.degree(1)\n",
    "\n",
    "hartford.successors(1)\n",
    "\n",
    "hartford.predecessors(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T23:41:45.618926Z",
     "start_time": "2018-08-02T23:41:44.317062Z"
    }
   },
   "outputs": [],
   "source": [
    "from regraph import Rule, plot_rule, plot_graph, plot_instance, find_matching\n",
    "#from regraph.default.primitives import *\n",
    "\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T00:00:56.580593Z",
     "start_time": "2018-08-03T00:00:56.575911Z"
    }
   },
   "outputs": [],
   "source": [
    "from production import IF, AND, OR, NOT, THEN, DELETE, forward_chain, pretty_goal_tree\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T00:18:13.674382Z",
     "start_time": "2018-08-03T00:18:13.666043Z"
    }
   },
   "outputs": [],
   "source": [
    "names= [ 'person mario',\n",
    "                      'person luigi',\n",
    "                      'person papa',\n",
    "                      'parent papa mario',\n",
    "                      'parent papa luigi' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T00:18:14.472652Z",
     "start_time": "2018-08-03T00:18:14.458302Z"
    }
   },
   "outputs": [],
   "source": [
    "person = IF( AND( 'person (?x)'),\n",
    "        THEN( 'self (?x) (?x)'))\n",
    "# x = x needed to make the sibling distinction.  \n",
    "\n",
    "child = IF( AND( 'parent (?x) (?y)'),\n",
    "        THEN( 'child (?y) (?x)'))\n",
    "# parent is already defined in assumptions so no need to make a rule for it! Turns out they have the same parent and \n",
    "# in the data parent papa mario','parent papa luigi' is the edge os the link between the relationship not \n",
    "# two separate parents. \n",
    "\n",
    "sibling = IF( AND( 'parent (?x) (?y)','parent (?x) (?z)',NOT( 'self (?y) (?z)')),\n",
    "        THEN( 'sibling (?y) (?z)'))\n",
    "# I made the mistake to include x as a sibling when x is root/papa, here they share one parent\n",
    "\n",
    "grandparent = IF( AND( 'parent (?x) (?y)', 'parent (?y) (?z)'),\n",
    "            THEN( 'grandparent (?x) (?z)'))\n",
    "# parents x is parent of y and y is parent of z (like a hierarchal line) making root x be grandparent of z\n",
    "\n",
    "grandchild = IF( AND( 'grandparent (?x) (?y)'),\n",
    "            THEN( 'grandchild (?y) (?x)'))\n",
    "\n",
    "cousin = IF( AND( 'sibling (?x) (?y)', 'parent (?x) (?z)','parent (?y) (?w)'),\n",
    "        THEN( 'cousin (?z) (?w)'))\n",
    "# they are siblings person x and y. They are  different parents x, y linked to different children z, w. But since the parents\n",
    "# are linked by sibling that makes the children cousins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T00:18:15.605956Z",
     "start_time": "2018-08-03T00:18:15.590332Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "generation = (1, 2, 3);\n",
    "female = 100\n",
    "male = 200\n",
    "gender = (female, male);\n",
    "yes = 101\n",
    "no = 202\n",
    "health = (yes, no);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T00:18:17.368225Z",
     "start_time": "2018-08-03T00:18:17.363096Z"
    }
   },
   "outputs": [],
   "source": [
    "relationship= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T00:18:19.308832Z",
     "start_time": "2018-08-03T00:18:19.302077Z"
    }
   },
   "outputs": [],
   "source": [
    "family = nx.DiGraph()\n",
    "nodes = [n for n in names][1:]                     \n",
    "\n",
    "node_names = [n[0] for n in nodes] # Get a list of only the node names \n",
    "\n",
    "\n",
    "\n",
    "edges = [tuple(e) for e in relationship][1:] \n",
    "\n",
    "family.add_nodes_from(node_names)\n",
    "family.add_edges_from(relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T00:18:21.793994Z",
     "start_time": "2018-08-03T00:18:21.786947Z"
    }
   },
   "outputs": [],
   "source": [
    "relationship_dict = {}\n",
    "gender_dict = {}\n",
    "birth_dict = {}\n",
    "death_dict = {}\n",
    "id_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T00:18:25.131284Z",
     "start_time": "2018-08-03T00:18:25.125752Z"
    }
   },
   "outputs": [],
   "source": [
    "for node in nodes: # Loop through the list, one row at a time\n",
    "    relationship_dict[node[0]] = node[1]\n",
    "    gender_dict[node[0]] = node[2]\n",
    "    birth_dict[node[0]] = node[3]\n",
    "    death_dict[node[0]] = node[4]\n",
    "    id_dict[node[0]] = node[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T00:17:34.290292Z",
     "start_time": "2018-08-03T00:17:34.268072Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-8093fe8c2ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_node_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelationship_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'generation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_node_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_node_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbirth_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'birth_year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_node_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeath_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'death_year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_node_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sdfb_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myclone/lib/python3.6/site-packages/networkx/classes/function.py\u001b[0m in \u001b[0;36mset_node_attributes\u001b[0;34m(G, name, values)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "nx.set_node_attributes(family, relationship_dict, '')\n",
    "nx.set_node_attributes(family, gender_dict, 'gender')\n",
    "nx.set_node_attributes(family, birth_dict, 'birth_year')\n",
    "nx.set_node_attributes(family, death_dict, 'death_year')\n",
    "nx.set_node_attributes(family, id_dict, 'sdfb_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = Rule.from_transform(pattern)\n",
    "rule.inject_merge_nodes([\"gene1\", \"gene2\"])\n",
    "rule.inject_add_node(\"new_node\")\n",
    "rule.inject_add_edge(\"residue\", \"new_node\")\n",
    "rule.inject_clone_node(\"residue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rule(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rule.to_commands())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "add_nodes_from(g, [1, 2, 3, 4, 5, 6])\n",
    "add_edges_from(g, [(2, 1), (2, 3), (3, 4), (3, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = plot_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T21:54:15.601337Z",
     "start_time": "2018-08-02T21:54:15.561585Z"
    }
   },
   "source": [
    "\n",
    "#subgraph(G, nbunch) #- induce subgraph of G on nodes in nbunch\n",
    "union(G,hartford) #- graph union \n",
    "disjoint_union(G1,G2) #- graph union assuming all nodes are different \n",
    "cartesian_product(G1,G2) #- return Cartesian product graph \n",
    "compose(G1,G2) #- combine graphs identifying nodes common to both \n",
    "complement(G) #- graph complement \n",
    "create_empty_copy(G) #- return an empty copy of the same graph class \n",
    "convert_to_undirected(G)# - return an undirected representation of G \n",
    "convert_to_directed(G) #- return a directed representation of G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Force-directed_graph_drawing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myclone]",
   "language": "python",
   "name": "conda-env-myclone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "415.85px",
    "left": "947px",
    "right": "-17px",
    "top": "-11px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
